#!/usr/bin/env python3
"""
–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–æ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏.
–†–∞–±–æ—Ç–∞–µ—Ç —Å —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–º–∏ –¥–∞–Ω–Ω—ã–º–∏ –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏ –ø–æ–ª–Ω–æ–≥–æ —Ü–∏–∫–ª–∞.
"""

import os
import json
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import logging
from typing import Dict, Any, Optional
import joblib
from dotenv import load_dotenv

# Local imports
from predict import BitcoinPredictor
from train_demo import create_synthetic_data

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# –ó–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
load_dotenv()


def load_demo_model(model_path: Optional[str] = None) -> BitcoinPredictor:
    """
    –ó–∞–≥—Ä—É–∑–∫–∞ –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–æ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏.
    
    Args:
        model_path: –ü—É—Ç—å –∫ –º–æ–¥–µ–ª–∏
        
    Returns:
        –≠–∫–∑–µ–º–ø–ª—è—Ä BitcoinPredictor
    """
    if model_path is None:
        model_path = os.getenv('MODEL_PATH', 'models/etf_model_v1.pkl')
    
    if not os.path.exists(model_path):
        raise FileNotFoundError(
            f"–ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {model_path}\n"
            "–°–Ω–∞—á–∞–ª–∞ –∑–∞–ø—É—Å—Ç–∏—Ç–µ: python train_demo.py"
        )
    
    return BitcoinPredictor(model_path)


def predict_with_synthetic_data(model_path: Optional[str] = None, days: int = 60) -> Dict[str, Any]:
    """
    –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö.
    
    Args:
        model_path: –ü—É—Ç—å –∫ –º–æ–¥–µ–ª–∏
        days: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–Ω–µ–π –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        
    Returns:
        –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
    """
    logger.info(f"–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –∏ —Å–æ–∑–¥–∞–Ω–∏–µ —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö –Ω–∞ {days} –¥–Ω–µ–π...")
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
    predictor = load_demo_model(model_path)
    
    # –°–æ–∑–¥–∞–Ω–∏–µ —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö
    data = create_synthetic_data(days)
    
    logger.info(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(data)} –∑–∞–ø–∏—Å–µ–π")
    
    # –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
    result = predictor.predict(data)
    
    # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –¥–∞–Ω–Ω—ã—Ö
    result['data_info'] = {
        'data_type': 'synthetic',
        'days': days,
        'last_price': float(data['close'].iloc[-1]),
        'last_date': data.index[-1].strftime('%Y-%m-%d'),
        'price_change_1d': float(data['close'].pct_change().iloc[-1]),
        'price_change_period': float((data['close'].iloc[-1] / data['close'].iloc[0]) - 1)
    }
    
    return result


def predict_with_json_data(model_path: Optional[str] = None) -> Dict[str, Any]:
    """
    –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º JSON –¥–∞–Ω–Ω—ã—Ö.
    
    Args:
        model_path: –ü—É—Ç—å –∫ –º–æ–¥–µ–ª–∏
        
    Returns:
        –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
    """
    logger.info("–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Å JSON –¥–∞–Ω–Ω—ã–º–∏...")
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
    predictor = load_demo_model(model_path)
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–º–µ—Ä–Ω—ã—Ö JSON –¥–∞–Ω–Ω—ã—Ö (–Ω—É–∂–Ω–æ –±–æ–ª—å—à–µ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤)
    dates = pd.date_range(start='2024-01-01', periods=50, freq='D')
    base_price = 45000
    
    sample_json = {
        "timestamp": [d.strftime('%Y-%m-%d') for d in dates],
        "open": [],
        "high": [],
        "low": [],
        "close": [],
        "volume": [],
        "etf_flow": []
    }
    
    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    np.random.seed(42)
    for i in range(50):
        change = np.random.normal(0, 0.02)
        if i == 0:
            price = base_price
        else:
            price = sample_json["close"][-1] * (1 + change)
        
        high = price * (1 + np.random.uniform(0, 0.01))
        low = price * (1 - np.random.uniform(0, 0.01))
        open_price = price * (1 + np.random.uniform(-0.005, 0.005))
        
        sample_json["open"].append(round(open_price, 2))
        sample_json["high"].append(round(high, 2))
        sample_json["low"].append(round(low, 2))
        sample_json["close"].append(round(price, 2))
        sample_json["volume"].append(round(np.random.uniform(1000, 2000), 0))
        sample_json["etf_flow"].append(round(np.random.normal(1000000, 200000), 2))
    
    # –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
    result = predictor.predict_from_json(sample_json)
    
    # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –¥–∞–Ω–Ω—ã—Ö
    result['data_info'] = {
        'data_type': 'json',
        'records': len(sample_json['timestamp']),
        'last_price': sample_json['close'][-1],
        'last_date': sample_json['timestamp'][-1]
    }
    
    return result


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–æ–Ω–Ω–æ–≥–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è."""
    logger.info("üîÆ –î–ï–ú–û–ù–°–¢–†–ê–¶–ò–û–ù–ù–û–ï –ü–†–ï–î–°–ö–ê–ó–ê–ù–ò–ï –¶–ï–ù–´ –ë–ò–¢–ö–û–ò–ù–ê")
    logger.info("=" * 60)
    
    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
    model_path = os.getenv('MODEL_PATH', 'models/etf_model_v1.pkl')
    
    try:
        # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Å —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–º–∏ –¥–∞–Ω–Ω—ã–º–∏
        print("\nüìä –ü–†–ï–î–°–ö–ê–ó–ê–ù–ò–ï –° –°–ò–ù–¢–ï–¢–ò–ß–ï–°–ö–ò–ú–ò –î–ê–ù–ù–´–ú–ò")
        print("-" * 50)
        
        result_synthetic = predict_with_synthetic_data(model_path, days=60)
        
        print(f"–°–∏–º–≤–æ–ª: BTCUSDT (—Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ)")
        print(f"–ü–æ—Å–ª–µ–¥–Ω—è—è —Ü–µ–Ω–∞: ${result_synthetic['data_info']['last_price']:,.2f}")
        print(f"–î–∞—Ç–∞: {result_synthetic['data_info']['last_date']}")
        print(f"–ò–∑–º–µ–Ω–µ–Ω–∏–µ –∑–∞ –¥–µ–Ω—å: {result_synthetic['data_info']['price_change_1d']:.2%}")
        print(f"–ò–∑–º–µ–Ω–µ–Ω–∏–µ –∑–∞ –ø–µ—Ä–∏–æ–¥: {result_synthetic['data_info']['price_change_period']:.2%}")
        print()
        print(f"–ü–†–û–ì–ù–û–ó:")
        print(f"–ù–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ: {result_synthetic['prediction_text']}")
        print(f"–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —Ä–æ—Å—Ç–∞: {result_synthetic['probability_up']:.2%}")
        print(f"–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –ø–∞–¥–µ–Ω–∏—è: {result_synthetic['probability_down']:.2%}")
        print(f"–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {result_synthetic['confidence']:.2%}")
        
        # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Å JSON –¥–∞–Ω–Ω—ã–º–∏
        print("\nüìã –ü–†–ï–î–°–ö–ê–ó–ê–ù–ò–ï –° JSON –î–ê–ù–ù–´–ú–ò")
        print("-" * 50)
        
        result_json = predict_with_json_data(model_path)
        
        print(f"–î–∞–Ω–Ω—ã–µ: {result_json['data_info']['records']} –∑–∞–ø–∏—Å–µ–π –∏–∑ JSON")
        print(f"–ü–æ—Å–ª–µ–¥–Ω—è—è —Ü–µ–Ω–∞: ${result_json['data_info']['last_price']:,.2f}")
        print(f"–î–∞—Ç–∞: {result_json['data_info']['last_date']}")
        print()
        print(f"–ü–†–û–ì–ù–û–ó:")
        print(f"–ù–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ: {result_json['prediction_text']}")
        print(f"–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —Ä–æ—Å—Ç–∞: {result_json['probability_up']:.2%}")
        print(f"–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –ø–∞–¥–µ–Ω–∏—è: {result_json['probability_down']:.2%}")
        print(f"–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {result_json['confidence']:.2%}")
        
        # –¢–æ–ø-5 –≤–∞–∂–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        if result_synthetic['feature_importance']:
            print(f"\nüìà –¢–û–ü-5 –í–ê–ñ–ù–´–• –ü–†–ò–ó–ù–ê–ö–û–í:")
            sorted_features = sorted(
                result_synthetic['feature_importance'].items(),
                key=lambda x: x[1],
                reverse=True
            )[:5]
            
            for i, (feature, importance) in enumerate(sorted_features, 1):
                print(f"{i}. {feature}: {importance:.4f}")
        
        print(f"\n‚è∞ –í—Ä–µ–º—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: {result_synthetic['timestamp']}")
        print(f"üìä –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ —Ç–æ—á–µ–∫ –¥–∞–Ω–Ω—ã—Ö: {result_synthetic['data_points_used']}")
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        output_file = f"prediction_demo_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        results = {
            'synthetic_prediction': result_synthetic,
            'json_prediction': result_json,
            'generated_at': datetime.now().isoformat()
        }
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False, default=str)
        
        print(f"\nüíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {output_file}")
        
        print("\n" + "="*60)
        print("üéâ –î–ï–ú–û–ù–°–¢–†–ê–¶–ò–û–ù–ù–û–ï –ü–†–ï–î–°–ö–ê–ó–ê–ù–ò–ï –ó–ê–í–ï–†–®–ï–ù–û –£–°–ü–ï–®–ù–û!")
        print("="*60)
        
    except FileNotFoundError as e:
        logger.error(f"–ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {e}")
        print("\n‚ùå –û–®–ò–ë–ö–ê: –ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞!")
        print("–°–Ω–∞—á–∞–ª–∞ –∑–∞–ø—É—Å—Ç–∏—Ç–µ –æ–±—É—á–µ–Ω–∏–µ:")
        print("   python train_demo.py")
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–æ–Ω–Ω–æ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–∏: {e}")
        raise


if __name__ == "__main__":
    main()
