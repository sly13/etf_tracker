#!/usr/bin/env python3
"""
–ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –º–æ–¥–µ–ª–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –ë–∏—Ç–∫–æ–∏–Ω–∞.
–î–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç –æ—Å–Ω–æ–≤–Ω—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –ø—Ä–æ–µ–∫—Ç–∞.
"""

import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import json


def create_sample_data() -> pd.DataFrame:
    """
    –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–º–µ—Ä–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏ —Ä–∞–±–æ—Ç—ã –º–æ–¥–µ–ª–∏.
    –í —Ä–µ–∞–ª—å–Ω–æ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏ –¥–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–∞—é—Ç—Å—è –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö.
    """
    print("üìä –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–º–µ—Ä–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö...")
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ä—è–¥–∞ –Ω–∞ 100 –¥–Ω–µ–π
    dates = pd.date_range(start='2024-01-01', periods=100, freq='D')
    
    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –æ —Ü–µ–Ω–µ –ë–∏—Ç–∫–æ–∏–Ω–∞
    np.random.seed(42)
    base_price = 45000
    
    # –°–æ–∑–¥–∞–Ω–∏–µ —Å–ª—É—á–∞–π–Ω–æ–≥–æ –±–ª—É–∂–¥–∞–Ω–∏—è —Å —Ç—Ä–µ–Ω–¥–æ–º
    returns = np.random.normal(0.001, 0.02, len(dates))  # –°—Ä–µ–¥–Ω–∏–π —Ä–æ—Å—Ç 0.1% –≤ –¥–µ–Ω—å
    prices = [base_price]
    
    for ret in returns[1:]:
        new_price = prices[-1] * (1 + ret)
        prices.append(new_price)
    
    # –°–æ–∑–¥–∞–Ω–∏–µ OHLCV –¥–∞–Ω–Ω—ã—Ö
    data = []
    for i, (date, close) in enumerate(zip(dates, prices)):
        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã—Ö OHLC –Ω–∞ –æ—Å–Ω–æ–≤–µ close
        volatility = np.random.uniform(0.01, 0.03)
        high = close * (1 + np.random.uniform(0, volatility))
        low = close * (1 - np.random.uniform(0, volatility))
        open_price = close * (1 + np.random.uniform(-volatility/2, volatility/2))
        volume = np.random.uniform(1000, 10000)
        
        # ETF –ø–æ—Ç–æ–∫–∏ (–º–æ–≥—É—Ç –±—ã—Ç—å –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–º–∏)
        etf_flow = np.random.normal(1000000, 500000)  # –°—Ä–µ–¥–Ω–∏–π –ø–æ—Ç–æ–∫ $1M
        
        data.append({
            'timestamp': date,
            'open': round(open_price, 2),
            'high': round(high, 2),
            'low': round(low, 2),
            'close': round(close, 2),
            'volume': round(volume, 0),
            'etf_flow': round(etf_flow, 2)
        })
    
    df = pd.DataFrame(data)
    df.set_index('timestamp', inplace=True)
    
    print(f"‚úÖ –°–æ–∑–¥–∞–Ω–æ {len(df)} –∑–∞–ø–∏—Å–µ–π —Å {datetime.strftime(dates[0], '%Y-%m-%d')} –ø–æ {datetime.strftime(dates[-1], '%Y-%m-%d')}")
    return df


def demonstrate_feature_engineering():
    """–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è —Å–æ–∑–¥–∞–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤."""
    print("\nüîß –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è —Å–æ–∑–¥–∞–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤...")
    
    # –ò–º–ø–æ—Ä—Ç —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ —Å–æ–∑–¥–∞–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö
    from train import FeatureEngineer
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–º–µ—Ä–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    data = create_sample_data()
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    feature_engineer = FeatureEngineer()
    features_df = feature_engineer.create_features(data)
    
    print(f"‚úÖ –ò—Å—Ö–æ–¥–Ω—ã—Ö –∫–æ–ª–æ–Ω–æ–∫: {len(data.columns)}")
    print(f"‚úÖ –ü–æ—Å–ª–µ —Å–æ–∑–¥–∞–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {len(features_df.columns)}")
    
    # –ü–æ–∫–∞–∑–∞—Ç—å –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ —Å–æ–∑–¥–∞–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
    feature_columns = [
        'return_prev', 'volatility', 'ma_7', 'ma_30',
        'etf_flow_change', 'rsi', 'macd'
    ]
    
    available_features = [col for col in feature_columns if col in features_df.columns]
    
    print(f"\nüìà –ü—Ä–∏–º–µ—Ä—ã —Å–æ–∑–¥–∞–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤:")
    for feature in available_features[:5]:  # –ü–æ–∫–∞–∑–∞—Ç—å –ø–µ—Ä–≤—ã–µ 5
        if not features_df[feature].isna().all():
            print(f"   {feature}: {features_df[feature].iloc[-1]:.4f}")
    
    return features_df


def demonstrate_model_training():
    """–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ (–±–µ–∑ —Ä–µ–∞–ª—å–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è)."""
    print("\nü§ñ –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –ø—Ä–æ—Ü–µ—Å—Å–∞ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏...")
    
    try:
        from train import BitcoinPredictor
        
        # –°–æ–∑–¥–∞–Ω–∏–µ —ç–∫–∑–µ–º–ø–ª—è—Ä–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞—Ç–µ–ª—è
        predictor = BitcoinPredictor()
        
        print("‚úÖ –ö–ª–∞—Å—Å BitcoinPredictor —Å–æ–∑–¥–∞–Ω")
        print(f"‚úÖ –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏: {predictor.model_params}")
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–º–µ—Ä–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        data = create_sample_data()
        
        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        X, y, feature_columns = predictor.prepare_data(data)
        
        print(f"‚úÖ –ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–æ {len(X)} –æ–±—Ä–∞–∑—Ü–æ–≤")
        print(f"‚úÖ –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {len(feature_columns)}")
        print(f"‚úÖ –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤: {y.value_counts().to_dict()}")
        
        # –ü–æ–∫–∞–∑–∞—Ç—å –ø—Ä–∏–º–µ—Ä—ã –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        print(f"\nüìä –ü—Ä–∏–º–µ—Ä—ã –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –ø–æ—Å–ª–µ–¥–Ω–µ–π —Å—Ç—Ä–æ–∫–∏:")
        last_row = X.iloc[-1]
        for i, (feature, value) in enumerate(last_row.items()):
            if i < 5:  # –ü–æ–∫–∞–∑–∞—Ç—å –ø–µ—Ä–≤—ã–µ 5 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
                print(f"   {feature}: {value:.4f}")
        
        return True
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏ –æ–±—É—á–µ–Ω–∏—è: {e}")
        return False


def demonstrate_prediction():
    """–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –ø—Ä–æ—Ü–µ—Å—Å–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è."""
    print("\nüîÆ –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –ø—Ä–æ—Ü–µ—Å—Å–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è...")
    
    try:
        from predict import BitcoinPredictor
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–º–µ—Ä–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON
        sample_json = {
            "timestamp": ["2024-01-01", "2024-01-02", "2024-01-03"],
            "open": [45000, 45500, 46000],
            "high": [46000, 46500, 47000],
            "low": [44000, 45000, 45500],
            "close": [45500, 46000, 46500],
            "volume": [1000, 1200, 1100],
            "etf_flow": [1000000, 1500000, 1200000]
        }
        
        print("‚úÖ –°–æ–∑–¥–∞–Ω –ø—Ä–∏–º–µ—Ä JSON –¥–∞–Ω–Ω—ã—Ö")
        print(f"   –î–∞–Ω–Ω—ã–µ: {len(sample_json['timestamp'])} –∑–∞–ø–∏—Å–µ–π")
        
        # –ü–æ–∫–∞–∑–∞—Ç—å —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–∞–Ω–Ω—ã—Ö
        print(f"\nüìã –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–∞–Ω–Ω—ã—Ö:")
        for key, values in sample_json.items():
            if key != 'timestamp':
                print(f"   {key}: {values}")
        
        print("\nüí° –í —Ä–µ–∞–ª—å–Ω–æ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏:")
        print("   1. –ó–∞–≥—Ä—É–∑–∏—Ç–µ –æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å: predictor = BitcoinPredictor('models/etf_model_v1.pkl')")
        print("   2. –í—ã–ø–æ–ª–Ω–∏—Ç–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ: result = predictor.predict_from_json(sample_json)")
        print("   3. –ü–æ–ª—É—á–∏—Ç–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç: –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —Ä–æ—Å—Ç–∞, –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ, —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å")
        
        return True
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: {e}")
        return False


def show_usage_instructions():
    """–ü–æ–∫–∞–∑–∞—Ç—å –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –ø–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é."""
    print("\nüìñ –ò–ù–°–¢–†–£–ö–¶–ò–ò –ü–û –ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–Æ")
    print("=" * 50)
    
    print("\n1Ô∏è‚É£ –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –æ–∫—Ä—É–∂–µ–Ω–∏—è:")
    print("   python3 -m venv venv")
    print("   source venv/bin/activate")
    print("   pip install -r requirements.txt")
    
    print("\n2Ô∏è‚É£ –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏:")
    print("   cp env.example .env")
    print("   # –û—Ç—Ä–µ–¥–∞–∫—Ç–∏—Ä—É–π—Ç–µ .env —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –ë–î")
    
    print("\n3Ô∏è‚É£ –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏:")
    print("   python test_setup.py")
    
    print("\n4Ô∏è‚É£ –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏:")
    print("   python train.py")
    
    print("\n5Ô∏è‚É£ –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –ø—Ä–æ–≥–Ω–æ–∑–∞:")
    print("   python predict.py")
    
    print("\n6Ô∏è‚É£ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –≤ –∫–æ–¥–µ:")
    print("""
   from predict import load_model
   
   # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
   predictor = load_model('models/etf_model_v1.pkl')
   
   # –ü—Ä–æ–≥–Ω–æ–∑ —Å –¥–∞–Ω–Ω—ã–º–∏ –∏–∑ –ë–î
   result = predictor.predict_from_database()
   print(f"–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —Ä–æ—Å—Ç–∞: {result['probability_up']:.2%}")
   """)


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏."""
    print("üöÄ –î–ï–ú–û–ù–°–¢–†–ê–¶–ò–Ø –ü–†–û–ï–ö–¢–ê –ü–†–ï–î–°–ö–ê–ó–ê–ù–ò–Ø –ë–ò–¢–ö–û–ò–ù–ê")
    print("=" * 60)
    
    # –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è —Å–æ–∑–¥–∞–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö
    data = create_sample_data()
    print(f"   –ü–æ—Å–ª–µ–¥–Ω—è—è —Ü–µ–Ω–∞: ${data['close'].iloc[-1]:,.2f}")
    print(f"   –ò–∑–º–µ–Ω–µ–Ω–∏–µ –∑–∞ –ø–µ—Ä–∏–æ–¥: {((data['close'].iloc[-1] / data['close'].iloc[0]) - 1):.2%}")
    
    # –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è —Å–æ–∑–¥–∞–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    features_df = demonstrate_feature_engineering()
    
    # –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏
    training_ok = demonstrate_model_training()
    
    # –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
    prediction_ok = demonstrate_prediction()
    
    # –ü–æ–∫–∞–∑–∞—Ç—å –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏
    show_usage_instructions()
    
    # –ò—Ç–æ–≥–æ–≤—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
    print("\n" + "=" * 60)
    if training_ok and prediction_ok:
        print("üéâ –î–ï–ú–û–ù–°–¢–†–ê–¶–ò–Ø –ó–ê–í–ï–†–®–ï–ù–ê –£–°–ü–ï–®–ù–û!")
        print("\n–ü—Ä–æ–µ–∫—Ç –≥–æ—Ç–æ–≤ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é. –°–ª–µ–¥—É–π—Ç–µ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è–º –≤—ã—à–µ.")
    else:
        print("‚ö†Ô∏è  –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —Å –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è–º–∏.")
        print("–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–∞—Å—Ç—Ä–æ–π–∫—É –æ–∫—Ä—É–∂–µ–Ω–∏—è –ø–µ—Ä–µ–¥ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º.")
    
    print("=" * 60)


if __name__ == "__main__":
    main()
